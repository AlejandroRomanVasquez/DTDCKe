{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f239ec2a",
   "metadata": {},
   "source": [
    "### Rpy2 package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6e11e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c00d949",
   "metadata": {},
   "source": [
    "### Importing Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a43b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#knockpy\n",
    "import knockpy\n",
    "from knockpy.knockoff_filter import KnockoffFilter\n",
    "from knockpy.knockoff_stats import data_dependent_threshhold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44107efd",
   "metadata": {},
   "source": [
    "### Importing R packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a4072c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import r, pandas2ri\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "\n",
    "# import R's packages\n",
    "base = importr('base')\n",
    "glmnet = importr('glmnet')\n",
    "dplyr = importr('dplyr')\n",
    "rvinecopulib = importr('rvinecopulib')\n",
    "knockoff = importr('knockoff')\n",
    "sn = importr('sn')\n",
    "doMC = importr('doMC')\n",
    "foreach = importr('foreach')\n",
    "doParallel = importr('doParallel')\n",
    "TSP = importr('TSP')\n",
    "VineCopula = importr('VineCopula')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a4df3e",
   "metadata": {},
   "source": [
    "### Auxiliary used-defined  python functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9941d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dvine_knockoff_filter(X, y, M, M_lasso, alpha, lasso_family, vinecop_family, n_cores):\n",
    "  \"\"\"\" \n",
    "  This function runs the knockoff filter with e-values for dvine knockoffs.\n",
    "  \n",
    "  Returns a numpy array\n",
    "  \n",
    "  Parameters \n",
    "  ---------- \n",
    "  X : numpy array --> Matrix of predictors\n",
    "  y : numpy array --> Response variable\n",
    "  M : int -> number of derandomize knockoffs runs\n",
    "  alpha : float -> FDR target level for the derandomize knockoffs using e-values\n",
    "  lasso_family : str-> related to linear regression or logistic regresion (\"gaussian\" or \"binomial\")\n",
    "  vinecop_family: String related to the family of pair copulas used in the dvine fitting. \n",
    "                 Common options are \"parametric\", \"nonparametric\", \"onepar\". More details can be found\n",
    "                 in the documentation of R package rvinecopulib\n",
    "                  https://cran.r-project.org/web/packages/rvinecopulib/rvinecopulib.pdf\n",
    "  n_cores: int -> number of cores for parallel processing               \n",
    "  \"\"\" \n",
    "  #Transformation to a pandas data.frame\n",
    "  X = pd.DataFrame(X)  \n",
    "  y = pd.DataFrame(y)\n",
    "    \n",
    "  #Convertion of the pandas dataframe to a R dataframe  \n",
    "  with localconverter(robjects.default_converter + pandas2ri.converter):\n",
    "    r_X = robjects.conversion.py2rpy(X)\n",
    "    r_y = robjects.conversion.py2rpy(y)\n",
    "  \n",
    "  #Object conversion\n",
    "  robjects.globalenv[\"X\"] = r_X\n",
    "  robjects.globalenv[\"y\"] = r_y\n",
    "\n",
    "  #Object conversion\n",
    "  robjects.globalenv[\"M\"] = M\n",
    "  robjects.globalenv[\"M_lasso\"] = M_lasso  \n",
    "  robjects.globalenv[\"alpha\"] = alpha\n",
    "  robjects.globalenv[\"vinecop_family\"] = vinecop_family\n",
    "  robjects.globalenv[\"lasso_family\"] = lasso_family\n",
    "  robjects.globalenv[\"n_cores\"] = n_cores\n",
    "\n",
    "    \n",
    "  #Fitting \n",
    "  robjects.r('''\n",
    "  \n",
    "           #Dvine fitting \n",
    "           dvine_distributions <- X_Xk_dvine_distributions(X, vinecop_family, n_cores) \n",
    "            \n",
    "           y <- unlist(y) #This transformation is required because the object Python conversion\n",
    "           \n",
    "           #Aplication of the derandomized procedure using e-values\n",
    "           res <- ekn_dvines(X, y, dvine_distributions, M, M_lasso, alpha, gamma=alpha/2, \n",
    "           lasso_family, n_cores)\n",
    "           \n",
    "           #Vector of integers that indicates the selected non-nulls position \n",
    "           rej <- res$rej\n",
    "           #To account for Python indexing, it is necessary to subtract 1 from the vector elements.\n",
    "           rej <- rej-1 \n",
    "       \n",
    "        \n",
    "        ''')\n",
    "\n",
    "\n",
    "  r_rej = robjects.globalenv['rej']  \n",
    "  #Transformation to a numpy array\n",
    "  np_rej = np.array(r_rej, dtype=np.int32)\n",
    "    \n",
    "  return np_rej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff3f8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dvine_order(X):\n",
    "  \"\"\"\" \n",
    "  This function runs an heuristic procedure to determine the \n",
    "  order for the first tree in a D-vine structure using the TSP R package\n",
    "  \n",
    "  Returns a numpy array\n",
    "  \n",
    "  Parameters \n",
    "  ---------- \n",
    "  X : numpy array --> Matrix of predictors\n",
    "           \n",
    "  \"\"\" \n",
    "  #Transformation to a pandas data.frame\n",
    "  X = pd.DataFrame(X)  \n",
    "     \n",
    "  #Convertion of the pandas dataframe to a R dataframe  \n",
    "  with localconverter(robjects.default_converter + pandas2ri.converter):\n",
    "    r_X = robjects.conversion.py2rpy(X)\n",
    "  \n",
    "  #Object conversion\n",
    "  robjects.globalenv[\"X\"] = r_X\n",
    "    \n",
    "  #Fitting \n",
    "  robjects.r('''\n",
    "  \n",
    "           #Heuristic procedure to determine the order for the first tree in a D-vine structure\n",
    "           dvine_order <- get_dvine_order(X)\n",
    "      \n",
    "        ''')\n",
    "\n",
    "  r_dvine_order = robjects.globalenv['dvine_order']  \n",
    "  #Transformation to a numpy array\n",
    "  np_dvine_order = np.array(r_dvine_order, dtype=np.int32)\n",
    "    \n",
    "  return np_dvine_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd85ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_knockoff_filter(X, y, M, M_lasso, alpha, lasso_family, n_cores):\n",
    "  \"\"\"\" \n",
    "  This function runs the knockoff filter with e-values for Gaussian knockoffs.\n",
    "  The knockoffs method is implemented via the Python-package knockpy\n",
    "  \n",
    "  Returns a numpy array\n",
    "  \n",
    "  Parameters \n",
    "  ---------- \n",
    "  X : numpy array --> Matrix of predictors\n",
    "  y : numpy array --> Response variable\n",
    "  M : int -> number of derandomize knockoffs runs\n",
    "  alpha : float -> FDR target level for the derandomize knockoffs using e-values\n",
    "  lasso_family : str-> related to linear regression or logistic regresion (\"gaussian\" or \"binomial\")\n",
    "  n_cores: int -> number of cores for parallel processing               \n",
    "  \"\"\"     \n",
    "  #Transformation to a pandas data.frame\n",
    "  X = pd.DataFrame(X)  \n",
    "  y = pd.DataFrame(y)\n",
    "    \n",
    "  #Convertion of the pandas dataframe to a R dataframe  \n",
    "  with localconverter(robjects.default_converter + pandas2ri.converter):\n",
    "    r_X = robjects.conversion.py2rpy(X)\n",
    "    r_y = robjects.conversion.py2rpy(y)\n",
    "  \n",
    "  robjects.globalenv[\"X\"] = r_X\n",
    "  robjects.globalenv[\"y\"] = r_y\n",
    "\n",
    "  #Object conversion\n",
    "  robjects.globalenv[\"M\"] = M\n",
    "  robjects.globalenv[\"M_lasso\"] = M_lasso  \n",
    "  robjects.globalenv[\"alpha\"] = alpha\n",
    "  robjects.globalenv[\"lasso_family\"] = lasso_family\n",
    "  robjects.globalenv[\"n_cores\"] = n_cores\n",
    "\n",
    "    \n",
    "  #Fitting \n",
    "  robjects.r(''' \n",
    "  \n",
    "           y <- unlist(y) #This transformation is required because the object Python conversion\n",
    " \n",
    "           #Aplication of the derandomized procedure using e-values\n",
    "           res <- ekn_gaussian(X, y, ls_Xk_norm, M, M_lasso, alpha, gamma=alpha/2, \n",
    "           lasso_family, n_cores)\n",
    "           \n",
    "           #Vector of integers that indicates the selected non-nulls position \n",
    "           rej <- res$rej\n",
    "           rej <- rej-1 #Subtraction is done for python index\n",
    "              \n",
    "        ''')\n",
    "\n",
    "\n",
    "  r_rej = robjects.globalenv['rej']  \n",
    "  #Transformation to a numpy array\n",
    "  np_rej = np.array(r_rej, dtype=np.int32)\n",
    "    \n",
    "  return np_rej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65601c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_order_knockoff_filter(X, y, M, M_lasso, alpha, lasso_family, n_cores):\n",
    "  \"\"\"\" \n",
    "  This function runs the knockoff filter with e-values for second order knockoffs.\n",
    "  The second order knockoffs method is implemented via the R-package knockoffs\n",
    "  \n",
    "  Returns a numpy array\n",
    "  \n",
    "  Parameters \n",
    "  ---------- \n",
    "  X : numpy array --> Matrix of predictors\n",
    "  y : numpy array --> Response variable\n",
    "  M : int -> number of derandomize knockoffs runs\n",
    "  alpha : float -> FDR target level for the derandomize knockoffs using e-values\n",
    "  lasso_family : str-> related to linear regression or logistic regresion (\"gaussian\" or \"binomial\")\n",
    "  n_cores: int -> number of cores for parallel processing               \n",
    "  \"\"\"    \n",
    "  #Transformation to a pandas data.frame\n",
    "  X = pd.DataFrame(X)  \n",
    "  y = pd.DataFrame(y)\n",
    "    \n",
    "  #Convertion of the pandas dataframe to a R dataframe  \n",
    "  with localconverter(robjects.default_converter + pandas2ri.converter):\n",
    "    r_X = robjects.conversion.py2rpy(X)\n",
    "    r_y = robjects.conversion.py2rpy(y)\n",
    "\n",
    "  #Object conversion\n",
    "  robjects.globalenv[\"X\"] = r_X\n",
    "  robjects.globalenv[\"y\"] = r_y\n",
    "\n",
    "  #Object conversion\n",
    "  robjects.globalenv[\"M\"] = M\n",
    "  robjects.globalenv[\"M_lasso\"] = M_lasso  \n",
    "  robjects.globalenv[\"alpha\"] = alpha\n",
    "  robjects.globalenv[\"lasso_family\"] = lasso_family\n",
    "  robjects.globalenv[\"n_cores\"] = n_cores\n",
    "\n",
    "    \n",
    "  #Fitting \n",
    "  robjects.r('''           \n",
    "           \n",
    "           y <- unlist(y) #This transformation is required because the object Python conversion\n",
    "           X <- as.matrix(X) #Transformation needed to applied the second order knockoffs\n",
    "           \n",
    "           #Aplication of the derandomized procedure using e-values\n",
    "           res <- ekn_second_order(X, y, M, M_lasso, alpha, gamma=alpha/2, \n",
    "           lasso_family, n_cores)\n",
    "           \n",
    "           #Vector of integers that indicates the selected non-nulls position \n",
    "           rej <- res$rej\n",
    "           rej <- rej-1 #Subtraction is done for python index\n",
    "              \n",
    "        ''')\n",
    "\n",
    "  r_rej = robjects.globalenv['rej']  \n",
    "  #Transformation to a numpy array\n",
    "  np_rej = np.array(r_rej, dtype=np.int32)\n",
    "    \n",
    "  return np_rej"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b65904e",
   "metadata": {},
   "source": [
    "### R functions related to dvines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df05a873",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "#get_dvine_order() -->   This function runs an heuristic procedure to determine the \n",
    "#order for the first tree in a D-vine structure using the TSP R package to solve \n",
    "#the traveling salesman problem. To solve it, we need to identify the shortest \n",
    "#Hamiltonian path by assigning weights based on the pairwise Kendall’s τ\n",
    "\n",
    "#Arguments:\n",
    "#X: matrix of predictors\n",
    "\n",
    "#Value: an integer vector with the new indices\n",
    "\n",
    "get_dvine_order <- function(X){\n",
    "\n",
    "    if (is.null(X)) {\n",
    "        stop(\"Argument X is null\")  \n",
    "    }\n",
    "    \n",
    "    #Matrix transformation\n",
    "    X <- as.matrix(X)\n",
    "       \n",
    "    #Matrix of 1 - tau_ij\n",
    "    M_tau <- 1 - abs(TauMatrix(X))\n",
    "\n",
    "    #Hamiltonian path and solution (functions of package TSP)\n",
    "    hamilton <- insert_dummy(TSP(M_tau), label=\"cut\")\n",
    "    sol <- solve_TSP(hamilton,method=\"repetitive_nn\")\n",
    "\n",
    "    #Reordering\n",
    "    TSP_order <- cut_tour(sol,\"cut\")\n",
    "    names(TSP_order) <- NULL\n",
    "    \n",
    "    #To represent indices in Python, the vector requires a slight adjustment. \n",
    "    #Consequently, we subtract 1 from each element.\n",
    "    TSP_order <- TSP_order - 1\n",
    "    return(TSP_order)\n",
    "    \n",
    "}\n",
    "\n",
    "#X_Xk_dvine_distributions() --> Function to fit the dvine distribution for X and X_X matrices\n",
    "#Arguments:\n",
    "#X: matrix of predictors\n",
    "#vinecop_family : String related to the family of pair copulas used in the dvine fitting. \n",
    "#                 Common options are \"parametric\", \"nonparametric\", \"onepar\". More details can be found\n",
    "#                 in the documentation of R package rvinecopulib\n",
    "#                  https://cran.r-project.org/web/packages/rvinecopulib/rvinecopulib.pdf\n",
    "# n_cores: int -> number of cores for parallel processing\n",
    "\n",
    "#Value: This function returns a list that contains objects of class vinecop_dist for X and X_X\n",
    "#Note: more information about objects of class vinecop_dist can be found in \n",
    "#https://cran.r-project.org/web/packages/rvinecopulib/rvinecopulib.pdf\n",
    "\n",
    "X_Xk_dvine_distributions <- function(X, vinecop_family=\"parametric\", n_cores=1){\n",
    "\n",
    "    if (is.null(X)) {\n",
    "        stop(\"Argument X is null\")  \n",
    "    }\n",
    "       \n",
    "    #Number of variables p and sample size n\n",
    "    n <- dim(X)[1]\n",
    "    p <- dim(X)[2]\n",
    "\n",
    "\n",
    "    #dstructures for dvines\n",
    "    X_X_dstructure <- dvine_structure((2*p):1)\n",
    "    X_dstructure <- dvine_structure(p:1)\n",
    "\n",
    "    #Dataset column binding\n",
    "    X_X <- cbind(X,X)\n",
    "\n",
    "    #Seudo-Observations\n",
    "    u_X_X <- pseudo_obs(X_X)\n",
    "\n",
    "    #Fitting dvine distribution for X_X\n",
    "    dvine_fitting_time <- system.time(\n",
    "    fit_dvine_trunc <- vinecop(u_X_X, family_set=c(vinecop_family), structure= X_X_dstructure, presel=TRUE,\n",
    "                         selcrit='mbicv', par_method='mle', psi0=0.95, show_trace=FALSE, cores=n_cores, trunc_lvl=p-1)\n",
    "    )\n",
    "\n",
    "    #Printing dvine X_X fitting time\n",
    "    print(\"dvine fitting time in seconds:\")\n",
    "    print(dvine_fitting_time)\n",
    "\n",
    "    #Pair-copula list for X_X\n",
    "    X_X_dvine_pclist <- fit_dvine_trunc$pair_copulas\n",
    "\n",
    "    #dvine distribution for X_Xk \n",
    "    X_X_dvine_dist <- vinecop_dist(X_X_dvine_pclist, X_X_dstructure)\n",
    "\n",
    "    #Pair-copula list for X\n",
    "    X_dvine_pclist <- list(rep(list(\"\"),p-1))\n",
    "\n",
    "    #Iniziating with Independent copula\n",
    "    for (i in 1:(p-1)){\n",
    "    bicop <- bicop_dist(\"indep\",)\n",
    "    X_dvine_pclist[i] <- list(rep(list(bicop),p-i))\n",
    "    }\n",
    "\n",
    "    #Pair copula list just for X dependencies\n",
    "    for (i in 1:(p-1)){\n",
    "    J <- p-i\n",
    "\n",
    "    for (j in 1:J){\n",
    "      X_dvine_pclist[[i]][j] <- X_X_dvine_pclist[[i]][j] \n",
    "\n",
    "    } \n",
    "    }\n",
    "\n",
    "    # dvine distribution for X\n",
    "    X_dvine_dist <- vinecop_dist(X_dvine_pclist, X_dstructure)\n",
    "\n",
    "    #List with dvine distributions\n",
    "    dvine_distributions <- list(X_dvine_dist=X_dvine_dist, X_X_dvine_dist=X_X_dvine_dist)\n",
    "\n",
    "    return(dvine_distributions)\n",
    "}\n",
    "\n",
    "#create_dvine_Knockoffs() --> Function to sample dvine knockoffs\n",
    "#Arguments:\n",
    "#X: matrix of predictors\n",
    "#X_dvine_dist: Object of class vinecop_dist for X, contaning a list specifying the pair-copulas,\n",
    "#              structure, and variable types.\n",
    "#X_X_dvine_dist: Object of class vinecop_dist for X_X, \n",
    "#               contaning a list specifying the pair-copulas, structure, and variable types.\n",
    "# n_cores: int -> number of cores for parallel processing\n",
    "#Note: more information about objects of class vinecop_dist can be found in \n",
    "#https://cran.r-project.org/web/packages/rvinecopulib/rvinecopulib.pdf\n",
    "\n",
    "#Value: This function returns a matrix Xk of knockoffs\n",
    "\n",
    "create_dvine_Knockoffs <- function(X, X_dvine_dist , X_X_dvine_dist, n_cores=1){\n",
    "\n",
    "    if (is.null(X)) {\n",
    "        stop(\"Argument X is null\")  \n",
    "    }\n",
    "    if (is.null( X_dvine_dist)) {\n",
    "        stop(\"Argument X_dvine_dist is null\")  \n",
    "    }\n",
    "    if (is.null( X_X_dvine_dist)) {\n",
    "        stop(\"Argument X_X_dvine_dist is null\")  \n",
    "    }\n",
    "    \n",
    "        \n",
    "    #Number of variables p and sample size n\n",
    "    n <- dim(X)[1]\n",
    "    p <- dim(X)[2]\n",
    "    \n",
    "    \n",
    "    #Pseudo observations\n",
    "    u_X <- pseudo_obs(X)\n",
    "\n",
    "    #Independent uniforms w\n",
    "    w_X <- rosenblatt(x=u_X, model=X_dvine_dist, cores = n_cores)\n",
    "    w_Xk <- matrix(runif(n=p*n,min=0,max=1),nrow=n,ncol=p)\n",
    "    w_X_Xk <- cbind(w_X,w_Xk)\n",
    "\n",
    "    #Knockoff sampling Xk\n",
    "    u_X_Xk <- inverse_rosenblatt(u=w_X_Xk, model= X_X_dvine_dist, cores = n_cores)\n",
    "    u_Xk <- u_X_Xk[,(p+1):(2*p)]\n",
    "\n",
    "    #Marginal transformation\n",
    "    Xk <- X\n",
    "    for(i in 1:p) {   \n",
    "        Xk[,i] <- as.vector(quantile(X[,i], probs=punif(u_Xk[,i],min=0, max=1), type=8))\n",
    "    }\n",
    "\n",
    "    return(Xk)\n",
    "}\n",
    "\n",
    "# stable_lasso_glmnet()--> Function to fit a regularized lasso regresion model using \n",
    "#some functions of the R package glmnet.\n",
    "#It implements the stabilizing procedure of Roberts and Nowak (2014) to diminish sensitivity\n",
    "#to the fold assignment used in cross-validation to select the hyperparameter lambda\n",
    "\n",
    "#Arguments:\n",
    "#X: matrix of predictors\n",
    "#y: vector or matrix of response\n",
    "#lasso_family: a string to select linear regression \"gaussian\" or logistic regression \"binomial\"\n",
    "#M_lasso: integer related to the number of runs for the stabilzation against CV\n",
    "#n_folds: integer indicating the number of cross validations\n",
    "#Note: more information about the R package glmnet can be found in \n",
    "#https://cran.r-project.org/web/packages/glmnet/glmnet.pdf\n",
    "#Note 2: this function runs in parallel for the stabilzation against CV\n",
    "\n",
    "#Value: This function returns a vector of the estimated coeficientes (without the intercept)\n",
    "\n",
    "\n",
    "stable_lasso_glmnet <- function(X, y, lasso_family, M_lasso = 10, n_folds = 5){\n",
    "\n",
    "    if (is.null(X)) {\n",
    "        stop(\"Argument X is missing\")  \n",
    "    }\n",
    "    if (is.null(y)) {\n",
    "        stop(\"Argument y is missing\")  \n",
    "    }\n",
    "    if (is.null( lasso_family )) {\n",
    "        stop(\"Argument lasso_family is missing\")  \n",
    "    }\n",
    "\n",
    "    \n",
    "    y_vec <- as.vector(y)\n",
    "    X_matrix <- as.matrix(X)\n",
    "\n",
    "\n",
    "    #Stabilizing the lasso against CV (Roberts and Nowak, 2014)\n",
    "    lambdas <- rep(0,M_lasso)\n",
    "\n",
    "    time_cv <- system.time(  \n",
    "        lambdas <- foreach(i = 1:M_lasso, .combine=c,.packages=c(\"glmnet\")) %dopar% {\n",
    "        set.seed(i)\n",
    "        cvfit <- cv.glmnet(X_matrix, y_vec, alpha=1, family = lasso_family, nfolds = n_folds, standardize = TRUE)\n",
    "        cvfit$lambda.min\n",
    "        }\n",
    "    )\n",
    "\n",
    "    #Selecting the median of the lambdas distribution\n",
    "    lambda50 <- as.numeric(quantile(lambdas,probs=0.5))\n",
    "    fit_coef <- coef(glmnet(X_matrix, y_vec, alpha = 1, lambda = lambda50, family = lasso_family, standardize = TRUE))\n",
    "\n",
    "    fit_coef_vec <- as.vector(fit_coef)\n",
    "    fit_coef_vec <- fit_coef_vec[-1] \n",
    "\n",
    "    return(fit_coef_vec)\n",
    "}\n",
    "\n",
    "# ekn_dvines()--> Function to derandomized knockoffs using e-values for FDR control. This function\n",
    "# considers the dvine knockoff procedure.\n",
    "#The code to implement this function is adapted from \n",
    "#https://github.com/zhimeir/derandomized_knockoffs_fdr\n",
    "\n",
    "#Arguments:\n",
    "#X: matrix of predictors\n",
    "#y: vector or matrix of response\n",
    "#M: integer denoting the number of generated copies of the knockff matrix Xk.\n",
    "#dvine_distributions: list that contains objects of class vinecop_dist for X and X_X\n",
    "#M_lasso: integer related to the number of runs for the stabilzation against CV\n",
    "#alpha: integer indicating FDR target level\n",
    "#gamma: integer denoting target level for the knockoff threshold. According to Ren & Barber (2023),\n",
    "#       experimentally, gamma=alpha/2 works well.           \n",
    "#lasso_family: a string to select linear regression \"gaussian\" or logistic regression \"binomial\" \n",
    "#n_cores: int -> number of cores for parallel processing\n",
    "\n",
    "#Note: the knockoff.threshold() function from the R knockoff package is used for \n",
    "#setting the Knockoff rejection threshold (https://cran.r-project.org/web/packages/knockoff/knockoff.pdf)\n",
    "\n",
    "#Value: This function returns a list with the selected variables of the procedure\n",
    "\n",
    "ekn_dvines <- function(X, y, dvine_distributions, M=50, M_lasso=10, alpha=0.2, gamma=0.1, lasso_family, n_cores=1){\n",
    "\n",
    "    if (is.null(X)) {\n",
    "        stop(\"Argument X is missing\")  \n",
    "    }\n",
    "    if (is.null(y)) {\n",
    "        stop(\"Argument y is missing\")  \n",
    "    }\n",
    "    if (is.null( dvine_distributions )) {\n",
    "        stop(\"Argument dvine_distributions is missing\")  \n",
    "    }\n",
    "    if (is.null( lasso_family )) {\n",
    "        stop(\"Argument lasso_family is missing\")  \n",
    "    }\n",
    "       \n",
    "      \n",
    "    #Number of variables p and sample size n  \n",
    "    n <- dim(X)[1]\n",
    "    p <- dim(X)[2]\n",
    "\n",
    "    #Initial matrix of E-values \n",
    "    E <- matrix(0, M, p)\n",
    "    \n",
    "    for(m in 1:M){\n",
    "        \n",
    "        set.seed(m) #The seed is adjusted for reproducibility issues in the simulations.\n",
    "        \n",
    "        #dvine Knockoffs sampling\n",
    "        Xk <- create_dvine_Knockoffs(X, X_dvine_dist = dvine_distributions$X_dvine_dist ,\n",
    "                                     X_X_dvine_dist =dvine_distributions$X_X_dvine_dist, n_cores)\n",
    "        \n",
    "        #X and Xk column binding\n",
    "        X_Xk <- cbind(X, Xk)\n",
    "        \n",
    "        #Estimated lasso coefficients for X_Xk\n",
    "        Z <- stable_lasso_glmnet(X_Xk, y, lasso_family, M_lasso)\n",
    "        \n",
    "        #Importance statistic\n",
    "        W <- abs(Z[1:p]) - abs(Z[(p+1):length(Z)])\n",
    "        \n",
    "        #Knockoff rejection threshold - conservative procedure (\"knockoffs+\" offset = 1)\n",
    "        tau <- stop_early(W, gamma, offset=1) \n",
    "        \n",
    "        #E-vales for all the variables (columns) for m run\n",
    "        E[m,] <- (W >= tau) / (1 + sum(W <= -tau))\n",
    "        \n",
    "   }\n",
    "    \n",
    "    #Averaging the e-values to select set of discoveries\n",
    "    E <- p*colMeans(E)\n",
    "    rej <- ebh(E, alpha)$rej\n",
    "    \n",
    "    return(list(rej = rej, E = E)) \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24b98e2",
   "metadata": {},
   "source": [
    "### R functions  to derandomized knockoffs using e-values for FDR control (Gaussian and second order knockoffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f33c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "ekn_gaussian <- function(X, y, ls_Xk_norm ,M, M_lasso, alpha, gamma, lasso_family, n_cores){\n",
    "  \n",
    "    if (is.null(X)) {\n",
    "        stop(\"Argument X is missing\")  \n",
    "    }\n",
    "    if (is.null(y)) {\n",
    "        stop(\"Argument y is missing\")  \n",
    "    }\n",
    "    if (is.null( lasso_family )) {\n",
    "        stop(\"Argument lasso_family is missing\")  \n",
    "    }\n",
    "    \n",
    "    \n",
    "    #Number of variables p and sample size n  \n",
    "    n <- dim(X)[1]\n",
    "    p <- dim(X)[2]\n",
    "\n",
    "    #Matrix of E-values \n",
    "    E <- matrix(0, M, p)\n",
    "\n",
    "    for(m in 1:M){\n",
    "        \n",
    "        set.seed(m) #The seed is adjusted for reproducibility issues in the simulations. \n",
    "        \n",
    "        #Gaussian Knockoffs copy selection from the list object\n",
    "        Xk <- ls_Xk_norm[[m]]\n",
    "        \n",
    "        #X and Xk column binding\n",
    "        X_Xk <- cbind(X, Xk)\n",
    "        \n",
    "        #Estimated lasso coefficients for X_Xk\n",
    "        Z <- stable_lasso_glmnet(X_Xk, y, lasso_family, M_lasso)\n",
    "        \n",
    "        #Importance statistics\n",
    "        W <- abs(Z[1:p]) - abs(Z[(p+1):length(Z)])\n",
    "        \n",
    "        #Knockoff rejection threshold - conservative procedure (\"knockoffs+\" offset = 1)\n",
    "        tau <- stop_early(W, gamma, offset=1) \n",
    "        \n",
    "        #E-vales for all the variables (columns) for m run\n",
    "        E[m,] <- (W >= tau) / (1 + sum(W <= -tau))\n",
    "        \n",
    "   }\n",
    "    \n",
    "    #Averaging the e-values to select set of discoveries\n",
    "    E <- p*colMeans(E)\n",
    "    rej <- ebh(E, alpha)$rej\n",
    "    \n",
    "    return(list(rej = rej, E = E)) \n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "ekn_second_order <- function(X, y, M, M_lasso, alpha, gamma, lasso_family, n_cores){\n",
    "   \n",
    "    if (is.null(X)) {\n",
    "        stop(\"Argument X is missing\")  \n",
    "    }\n",
    "    if (is.null(y)) {\n",
    "        stop(\"Argument y is missing\")  \n",
    "    }\n",
    "    if (is.null( lasso_family )) {\n",
    "        stop(\"Argument lasso_family is missing\")  \n",
    "    }\n",
    "\n",
    "     \n",
    "    #Number of variables p and sample size n  \n",
    "    n <- dim(X)[1]\n",
    "    p <- dim(X)[2]\n",
    "\n",
    "    #Matrix of E-values \n",
    "    E <- matrix(0, M, p)\n",
    "\n",
    "    for(m in 1:M){\n",
    "        \n",
    "        set.seed(m) #The seed is adjusted for reproducibility issues in the simulations.\n",
    "        \n",
    "        #Gaussian Knockoffs copy selection from the list object\n",
    "        Xk <- create.second_order(X)\n",
    "        \n",
    "        #X and Xk column binding\n",
    "        X_Xk <- cbind(X, Xk)\n",
    "        \n",
    "        #Estimated lasso coefficients for X_Xk\n",
    "        Z <- stable_lasso_glmnet(X_Xk, y, lasso_family, M_lasso)\n",
    "        \n",
    "        #Importance statistics\n",
    "        W <- abs(Z[1:p]) - abs(Z[(p+1):length(Z)])\n",
    "        \n",
    "        #Knockoff rejection threshold - conservative procedure (\"knockoffs+\" offset = 1)\n",
    "        tau <- stop_early(W, gamma, offset=1) \n",
    "        \n",
    "        #E-vales for all the variables (columns) for m run\n",
    "        E[m,] <- (W >= tau) / (1 + sum(W <= -tau))\n",
    "        \n",
    "   }\n",
    "    \n",
    "    #Averaging the e-values to select set of discoveries\n",
    "    E <- p*colMeans(E)\n",
    "    rej <- ebh(E, alpha)$rej\n",
    "    \n",
    "    return(list(rej = rej, E = E)) \n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf08b4cc",
   "metadata": {},
   "source": [
    "### Utility functions for the e-values procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454966fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "#These functions are obtained from\n",
    "#https://github.com/zhimeir/derandomized_knockoffs_fdr\n",
    "\n",
    "\n",
    "#####################################\n",
    "## The eBH procedure\n",
    "#####################################\n",
    "### Input: \n",
    "###   E: e-values\n",
    "###   alpha: target FDR level\n",
    "### Output:\n",
    "###   Variables selected by the e-BH procedure\n",
    "\n",
    "ebh <- function(E, alpha){\n",
    "  \n",
    "  p <- length(E)\n",
    "  E_ord <- order(E, decreasing = TRUE)\n",
    "  E <- sort(E, decreasing = TRUE)\n",
    "  comp <- E >= (p / alpha / (1:p))\n",
    "  id <- suppressWarnings(max(which(comp>0)))\n",
    "  if(id > 0){\n",
    "    rej <- E_ord[1:id]\n",
    "  }else{\n",
    "    rej <- NULL\n",
    "  }\n",
    "  return(list(rej = rej))\n",
    "}\n",
    "\n",
    "#######################################\n",
    "## Computing the early stopping time ##\n",
    "#######################################\n",
    "### Input:\n",
    "###   W: vector of knockoff feature importance statistics \n",
    "###   gamma: alpha_kn \n",
    "###   offset: value between 0 and 1\n",
    "### Output: \n",
    "###   The modified knockoff stopping time defined in (14)\n",
    "\n",
    "stop_early <- function(W, gamma, offset){\n",
    "  \n",
    "  tau <- alphakn_threshold(W, fdr =  gamma, offset = offset) \n",
    "  ord_W <- order(abs(W), decreasing = TRUE)\n",
    "  sorted_W <- W[ord_W]\n",
    "  \n",
    "  if(sum(W>0) >= 1 / gamma){\n",
    "    pos_ind <- which(sorted_W > 0)\n",
    "    tau1 <- sorted_W[pos_ind[ceiling(1/gamma)-1]]\n",
    "  }else{\n",
    "    tau1 <- 0\n",
    "  }\n",
    "  tau <- min(tau,tau1) \n",
    "\n",
    "  return(tau)\n",
    "}\n",
    "\n",
    "\n",
    "#######################################################\n",
    "## Compute stopping time w/ diff alpha_kn and offset ##\n",
    "#######################################################\n",
    "### Input:\n",
    "###   W: a length p vector of knockoff feature importance statistics\n",
    "###   fdr: the target FDR level\n",
    "###   offset: 0 or 1 \n",
    "### Output: \n",
    "###   the knockoff selection threshold\n",
    "\n",
    "alphakn_threshold <- function(W, fdr, offset) {\n",
    "  ts = sort(c(0, abs(W)))\n",
    "  ratio = sapply(ts, function(t)\n",
    "    (offset + sum(W <= -t)) / max(1, sum(W >= t)))\n",
    "  ok = which(ratio <= fdr)\n",
    "  ifelse(length(ok) > 0, ts[ok[1]], Inf)\n",
    "}\n",
    "                 \n",
    "                 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d366ddb",
   "metadata": {},
   "source": [
    "## NonGaussian  variables according to a Dvine distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed798d0f",
   "metadata": {},
   "source": [
    "### Simulation setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7202f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_initial = timer()\n",
    "\n",
    "nsim = 100 #Number of simulations\n",
    "n = 300  #Number of data points\n",
    "p = 100  #Number of features\n",
    "ri = 1 #Reproducibility indicator\n",
    "\n",
    "\n",
    "M = 50 #Number of runs for e-values procedure\n",
    "M_lasso = 10 #Number of runs for Lasso Stability against CV\n",
    "lasso_family= 'gaussian'\n",
    "vinecop_family = 'parametric'\n",
    "nonparametric_family = 'nonparametric'\n",
    "alpha = 0.2 #The rarget value for FDR control of derandomized knockoffs using e-values\n",
    "n_cores = 23\n",
    "\n",
    "\n",
    "#Correlation (rho)\n",
    "rho = 0.8\n",
    "np_rhos = np.repeat(rho,p-1) \n",
    "sp = 0.2 #Sparsity of the non-null vector (%)\n",
    "\n",
    "#Amplitude and coefficients\n",
    "amplitude = 8\n",
    "beta_factor = amplitude / math.sqrt(n)\n",
    "\n",
    "#From Python to R\n",
    "%R -i n\n",
    "%R -i ri \n",
    "%R -i n_cores\n",
    "\n",
    "#Parallel processing\n",
    "%R registerDoParallel(makeCluster(n_cores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4296d4",
   "metadata": {},
   "source": [
    "# Iteration 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd91e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Degrees of fredom (t-distribution)\n",
    "df_t = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d1577d",
   "metadata": {},
   "source": [
    "### Data simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329bf8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arrays and lists to save information\n",
    "ls_simulations = list(range(nsim))\n",
    "ls_beta = list(range(nsim))\n",
    "ls_X = list(range(nsim))\n",
    "ls_y = list(range(nsim))\n",
    "\n",
    "ti = timer() #Initial time\n",
    "\n",
    "\n",
    "for k in range(nsim):\n",
    "  \n",
    "  #Set seed for replication \n",
    "  np.random.seed(k + ri + 1000) #Python\n",
    "  %R -i k\n",
    "  %R set.seed(k + ri + 1000)  #R\n",
    "\n",
    "  #X simulation according to a t-tailed Markov Chain\n",
    "  X = knockpy.dgp.sample_ar1t(rhos=np_rhos, n=n, df_t= df_t)\n",
    "  ls_X[k] = X  \n",
    "    \n",
    "  # Creating random sparse coefficients\n",
    "  beta = knockpy.dgp.create_sparse_coefficients(p=p, sparsity=sp, sign_prob=0.5, coeff_size=beta_factor,coeff_dist='uniform')\n",
    "  ls_beta[k] = beta\n",
    "\n",
    "  # Response variable\n",
    "  y = np.dot(X, beta) + np.random.randn(n)\n",
    "  ls_y[k] = y\n",
    "    \n",
    "  #Data frame with simulated data (Y,X)\n",
    "  #df_X = pd.DataFrame(X)\n",
    "  #df_y = pd.DataFrame(y)\n",
    "  #ls_simulations[k] = pd.concat([df_y,df_X], axis=1)\n",
    "\n",
    "time_simulations_1 = timer() - ti      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2048283e",
   "metadata": {},
   "source": [
    "### Knockoff filters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7c50b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "# A list needed for the Gaussian Knockoff sampling procedure\n",
    "ls_Xk_norm <- list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7151a87c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np_Gaussian_Power = np.zeros(nsim)\n",
    "np_Gaussian_FDP = np.zeros(nsim)\n",
    "\n",
    "np_second_order_Power = np.zeros(nsim)\n",
    "np_second_order_FDP = np.zeros(nsim)\n",
    "\n",
    "np_dvine_Power = np.zeros(nsim)\n",
    "np_dvine_FDP = np.zeros(nsim)\n",
    "\n",
    "np_nonpar_dvine_Power = np.zeros(nsim)\n",
    "np_nonpar_dvine_FDP = np.zeros(nsim)\n",
    "\n",
    "ti = timer() #Initial time\n",
    "\n",
    "for k in range(nsim):\n",
    "  \n",
    "  %R set.seed(NULL) #The R seed is set inside each knockoff filter function\n",
    "  \n",
    "  #Loading simulations  \n",
    "  X = ls_X[k]  \n",
    "  y = ls_y[k]\n",
    "  beta = ls_beta[k]\n",
    "    \n",
    "  #1)  \n",
    "  #Gaussian Knockoffs\n",
    "  \n",
    "  #Defining the Gaussian sampler object\n",
    "  Gaussian_sampler_hat = knockpy.knockoffs.GaussianSampler(X, mu=None,\n",
    "                                                           Sigma=None,\n",
    "                                                           method='mvr', verbose=False)\n",
    "\n",
    "  #Sampling the Gaussian Knockoffs\n",
    "  for m in range(M):\n",
    "      np.random.seed(m)\n",
    "      Xk_norm = Gaussian_sampler_hat.sample_knockoffs()\n",
    "      %R -i Xk_norm\n",
    "      %R -i m\n",
    "      %R ls_Xk_norm[[m+1]] <- Xk_norm\n",
    "      %R rm(Xk_norm)  \n",
    "    \n",
    "  #Array of integers that indicates the non-nulls position  \n",
    "  just_rejections_gaussian = gaussian_knockoff_filter(X, y, M, M_lasso, alpha, lasso_family, n_cores)\n",
    "  \n",
    "  print(\"Gaussian selection:\")  \n",
    "  print(np.sort(just_rejections_gaussian))\n",
    " \n",
    "  #Array that indicates the rejections considering all the variables (0 null, 1 non-null)\n",
    "  rejections_gaussian = np.zeros(p)\n",
    "  rejections_gaussian[just_rejections_gaussian]=1\n",
    "   \n",
    "\n",
    "  #Power and FDP\n",
    "  np_Gaussian_Power[k] = np.dot(rejections_gaussian, beta != 0) / (beta != 0).sum()\n",
    "  np_Gaussian_FDP[k] = np.around(100*np.dot(rejections_gaussian, beta == 0) / max(1,rejections_gaussian.sum() ) )\n",
    "  print(f\"The knockoff GAUSSIAN filter POWER {100*np_Gaussian_Power[k]}% with a FDP of {np_Gaussian_FDP[k]}%\")\n",
    "  \n",
    "\n",
    "  #2)\n",
    "  #Second order knockoff filter    \n",
    "  just_rejections_second_order = second_order_knockoff_filter(X, y, M, M_lasso, alpha, lasso_family, n_cores)\n",
    "  \n",
    "  #Array of integers that indicates the non-nulls position\n",
    "  print(\"Second Order selection:\")  \n",
    "  print(np.sort(just_rejections_second_order))\n",
    "  \n",
    "  #Array that indicates the rejections considering all the variables (0 null, 1 non-null)\n",
    "  rejections_second_order = np.zeros(p)\n",
    "  rejections_second_order[just_rejections_second_order]=1\n",
    "    \n",
    "  #Power and FDP\n",
    "  np_second_order_Power[k] = np.dot(rejections_second_order, beta != 0) / (beta != 0).sum()\n",
    "  np_second_order_FDP[k] = np.around(100*np.dot(rejections_second_order, beta == 0) / max(1,rejections_second_order.sum()))\n",
    "  print(f\"The knockoff SECOND ORDER filter POWER {100*np_second_order_Power[k]}% with a FDP of {np_second_order_FDP[k]}%\")\n",
    "    \n",
    "  #3) dvine_order\n",
    "  #Heuristic procedure to determine the order for the first tree in a D-vine structure\n",
    "  dvine_order = get_dvine_order(X)\n",
    "\n",
    "  #New columns orders for X and beta\n",
    "  X_dvine_order = X[:,dvine_order]\n",
    "  beta_dvine_order  = beta[dvine_order]\n",
    "\n",
    "  #4) Parametric dvine\n",
    "    \n",
    "  just_rejections_dvines = dvine_knockoff_filter(X_dvine_order, y, M, M_lasso, alpha, lasso_family, vinecop_family, n_cores)\n",
    "    \n",
    "  #Array of integers that indicates the non-nulls position\n",
    "  print(\"DVINE selection (in dvine_order):\")\n",
    "  print(np.sort(just_rejections_dvines))\n",
    " \n",
    "  #Array that indicates the rejections considering all the variables (0 null, 1 non-null)\n",
    "  rejections_dvines = np.zeros(p)\n",
    "  rejections_dvines[just_rejections_dvines]=1\n",
    "    \n",
    "  #Power and FDP\n",
    "  np_dvine_Power[k] = np.dot(rejections_dvines, beta_dvine_order != 0) / (beta_dvine_order != 0).sum()\n",
    "  np_dvine_FDP[k] = np.around(100*np.dot(rejections_dvines, beta_dvine_order == 0) / max(1,rejections_dvines.sum()))\n",
    "  print(f\"The DVINE knockoff filter POWER {100*np_dvine_Power[k]}% with a FDP of {np_dvine_FDP[k]}% (DVINES)\")\n",
    "\n",
    "  #Deleting some objects\n",
    "  %R rm(dvine_distributions)  \n",
    "\n",
    "  #5) Nonparametric dvine\n",
    "  #dvine knockoff filter  \n",
    "  just_rejections_nonpar_dvines = dvine_knockoff_filter(X_dvine_order, y, M, M_lasso, alpha, lasso_family, nonparametric_family, n_cores)\n",
    "    \n",
    "  #Array of integers that indicates the non-nulls position\n",
    "  print(\"NONPARAMETRIC DVINE selection (in dvine_order):\")\n",
    "  print(np.sort(just_rejections_nonpar_dvines))\n",
    " \n",
    "  #Array that indicates the rejections considering all the variables (0 null, 1 non-null)\n",
    "  rejections_nonpar_dvines = np.zeros(p)\n",
    "  rejections_nonpar_dvines[just_rejections_nonpar_dvines]=1\n",
    "    \n",
    "  #Power and FDP\n",
    "  np_nonpar_dvine_Power[k] = np.dot(rejections_nonpar_dvines, beta_dvine_order != 0) / (beta_dvine_order != 0).sum()\n",
    "  np_nonpar_dvine_FDP[k] = np.around(100*np.dot(rejections_nonpar_dvines, beta_dvine_order == 0) / max(1,rejections_nonpar_dvines.sum()))\n",
    "  print(f\"The NONPARAMETRIC DVINE knockoff filter POWER {100*np_nonpar_dvine_Power[k]}% with a FDP of {np_nonpar_dvine_FDP[k]}% (NONPAR DVINES)\")\n",
    "\n",
    "  #Deleting some objects\n",
    "  %R rm(dvine_distributions)  \n",
    "  \n",
    "  del X, y, beta, dvine_order\n",
    "  del rejections_gaussian,rejections_second_order,rejections_dvines, rejections_nonpar_dvines\n",
    "        \n",
    "  print(f\"LOOP ITERATION: {k}\")\n",
    "   \n",
    "time_knockoffs_1 = timer() - ti  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcde74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array of varying feature\n",
    "np_varying_feature = np.repeat([df_t],repeats=nsim,axis=0)\n",
    "\n",
    "\n",
    "#Dataframe with simulated data\n",
    "df_simulations_results_1 = pd.DataFrame({'Varying feature':np_varying_feature,                                   \n",
    "                     'Gaussian Power(%)':np_Gaussian_Power*100, \n",
    "                     '2do Order Power(%)':np_second_order_Power*100,\n",
    "                     'Dvine Power(%)':np_dvine_Power*100,\n",
    "                     'Nonpar DvinePower(%)':np_nonpar_dvine_Power*100,\n",
    "                     'Gaussian FDP(%)':np_Gaussian_FDP,\n",
    "                     '2do Order FDP(%)':np_second_order_FDP, \n",
    "                     'Dvine FDP(%)':np_dvine_FDP,\n",
    "                     'Nonpar Dvine FDP(%)':np_nonpar_dvine_FDP})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1024afb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simulations_results_1.to_csv('t-Markov_results_1.csv')\n",
    "df_simulations_results_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d3a2d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_simulations_results_1.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9177e4e",
   "metadata": {},
   "source": [
    "# Iteration 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99b6e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Degrees of fredom (t-distribution)\n",
    "df_t = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651f37a1",
   "metadata": {},
   "source": [
    "### Data simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568bbf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arrays and lists to save information\n",
    "ls_simulations = list(range(nsim))\n",
    "ls_beta = list(range(nsim))\n",
    "ls_X = list(range(nsim))\n",
    "ls_y = list(range(nsim))\n",
    "\n",
    "ti = timer() #Initial time\n",
    "\n",
    "for k in range(nsim):\n",
    "  \n",
    "  #Set seed for replication \n",
    "  np.random.seed(k + ri + 2000) #Python\n",
    "  %R -i k\n",
    "  %R set.seed(k + ri + 2000)  #R\n",
    "\n",
    "  #X simulation according to a t-tailed Markov Chain\n",
    "  X = knockpy.dgp.sample_ar1t(rhos=np_rhos, n=n, df_t= df_t)\n",
    "  ls_X[k] = X  \n",
    "    \n",
    "  # Creating random sparse coefficients\n",
    "  beta = knockpy.dgp.create_sparse_coefficients(p=p, sparsity=sp, sign_prob=0.5, coeff_size=beta_factor,coeff_dist='uniform')\n",
    "  ls_beta[k] = beta\n",
    "\n",
    "  # Response variable\n",
    "  y = np.dot(X, beta) + np.random.randn(n)\n",
    "  ls_y[k] = y\n",
    "   \n",
    "  #Data frame with simulated data (Y,X)\n",
    "  #df_X = pd.DataFrame(X)\n",
    "  #df_y = pd.DataFrame(y)\n",
    "  #ls_simulations[k] = pd.concat([df_y,df_X], axis=1)\n",
    "\n",
    "time_simulations_2 = timer() - ti      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28133c8",
   "metadata": {},
   "source": [
    "### Knockoff filters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89f09b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "# A list needed for the Gaussian Knockoff sampling procedure\n",
    "ls_Xk_norm <- list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9e7b74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np_Gaussian_Power = np.zeros(nsim)\n",
    "np_Gaussian_FDP = np.zeros(nsim)\n",
    "\n",
    "np_second_order_Power = np.zeros(nsim)\n",
    "np_second_order_FDP = np.zeros(nsim)\n",
    "\n",
    "np_dvine_Power = np.zeros(nsim)\n",
    "np_dvine_FDP = np.zeros(nsim)\n",
    "\n",
    "np_nonpar_dvine_Power = np.zeros(nsim)\n",
    "np_nonpar_dvine_FDP = np.zeros(nsim)\n",
    "\n",
    "ti = timer() #Initial time\n",
    "\n",
    "for k in range(nsim):\n",
    "  \n",
    "  %R set.seed(NULL) #The R seed is set inside each knockoff filter function\n",
    "  \n",
    "  #Loading simulations  \n",
    "  X = ls_X[k]  \n",
    "  y = ls_y[k]\n",
    "  beta = ls_beta[k]\n",
    "    \n",
    "  #1)  \n",
    "  #Gaussian Knockoffs\n",
    "  \n",
    "  #Defining the Gaussian sampler object\n",
    "  Gaussian_sampler_hat = knockpy.knockoffs.GaussianSampler(X, mu=None,\n",
    "                                                           Sigma=None,\n",
    "                                                           method='mvr', verbose=False)\n",
    "\n",
    "  #Sampling the Gaussian Knockoffs\n",
    "  for m in range(M):\n",
    "      np.random.seed(m)\n",
    "      Xk_norm = Gaussian_sampler_hat.sample_knockoffs()\n",
    "      %R -i Xk_norm\n",
    "      %R -i m\n",
    "      %R ls_Xk_norm[[m+1]] <- Xk_norm\n",
    "      %R rm(Xk_norm)  \n",
    "    \n",
    "  #Array of integers that indicates the non-nulls position  \n",
    "  just_rejections_gaussian = gaussian_knockoff_filter(X, y, M, M_lasso, alpha, lasso_family, n_cores)\n",
    "  \n",
    "  print(\"Gaussian selection:\")  \n",
    "  print(np.sort(just_rejections_gaussian))\n",
    " \n",
    "  #Array that indicates the rejections considering all the variables (0 null, 1 non-null)\n",
    "  rejections_gaussian = np.zeros(p)\n",
    "  rejections_gaussian[just_rejections_gaussian]=1\n",
    "   \n",
    "\n",
    "  #Power and FDP\n",
    "  np_Gaussian_Power[k] = np.dot(rejections_gaussian, beta != 0) / (beta != 0).sum()\n",
    "  np_Gaussian_FDP[k] = np.around(100*np.dot(rejections_gaussian, beta == 0) / max(1,rejections_gaussian.sum() ) )\n",
    "  print(f\"The knockoff GAUSSIAN filter POWER {100*np_Gaussian_Power[k]}% with a FDP of {np_Gaussian_FDP[k]}%\")\n",
    "  \n",
    "\n",
    "  #2)\n",
    "  #Second order knockoff filter    \n",
    "  just_rejections_second_order = second_order_knockoff_filter(X, y, M, M_lasso, alpha, lasso_family, n_cores)\n",
    "  \n",
    "  #Array of integers that indicates the non-nulls position\n",
    "  print(\"Second Order selection:\")  \n",
    "  print(np.sort(just_rejections_second_order))\n",
    "  \n",
    "  #Array that indicates the rejections considering all the variables (0 null, 1 non-null)\n",
    "  rejections_second_order = np.zeros(p)\n",
    "  rejections_second_order[just_rejections_second_order]=1\n",
    "    \n",
    "  #Power and FDP\n",
    "  np_second_order_Power[k] = np.dot(rejections_second_order, beta != 0) / (beta != 0).sum()\n",
    "  np_second_order_FDP[k] = np.around(100*np.dot(rejections_second_order, beta == 0) / max(1,rejections_second_order.sum()))\n",
    "  print(f\"The knockoff SECOND ORDER filter POWER {100*np_second_order_Power[k]}% with a FDP of {np_second_order_FDP[k]}%\")\n",
    "    \n",
    "  #3) dvine_order\n",
    "  #Heuristic procedure to determine the order for the first tree in a D-vine structure\n",
    "  dvine_order = get_dvine_order(X)\n",
    "\n",
    "  #New columns orders for X and beta\n",
    "  X_dvine_order = X[:,dvine_order]\n",
    "  beta_dvine_order  = beta[dvine_order]\n",
    "\n",
    "  #4) Parametric dvine\n",
    "    \n",
    "  just_rejections_dvines = dvine_knockoff_filter(X_dvine_order, y, M, M_lasso, alpha, lasso_family, vinecop_family, n_cores)\n",
    "    \n",
    "  #Array of integers that indicates the non-nulls position\n",
    "  print(\"DVINE selection (in dvine_order):\")\n",
    "  print(np.sort(just_rejections_dvines))\n",
    " \n",
    "  #Array that indicates the rejections considering all the variables (0 null, 1 non-null)\n",
    "  rejections_dvines = np.zeros(p)\n",
    "  rejections_dvines[just_rejections_dvines]=1\n",
    "    \n",
    "  #Power and FDP\n",
    "  np_dvine_Power[k] = np.dot(rejections_dvines, beta_dvine_order != 0) / (beta_dvine_order != 0).sum()\n",
    "  np_dvine_FDP[k] = np.around(100*np.dot(rejections_dvines, beta_dvine_order == 0) / max(1,rejections_dvines.sum()))\n",
    "  print(f\"The DVINE knockoff filter POWER {100*np_dvine_Power[k]}% with a FDP of {np_dvine_FDP[k]}% (DVINES)\")\n",
    "\n",
    "  #Deleting some objects\n",
    "  %R rm(dvine_distributions)  \n",
    "\n",
    "  #5) Nonparametric dvine\n",
    "  #dvine knockoff filter  \n",
    "  just_rejections_nonpar_dvines = dvine_knockoff_filter(X_dvine_order, y, M, M_lasso, alpha, lasso_family, nonparametric_family, n_cores)\n",
    "    \n",
    "  #Array of integers that indicates the non-nulls position\n",
    "  print(\"NONPARAMETRIC DVINE selection (in dvine_order):\")\n",
    "  print(np.sort(just_rejections_nonpar_dvines))\n",
    " \n",
    "  #Array that indicates the rejections considering all the variables (0 null, 1 non-null)\n",
    "  rejections_nonpar_dvines = np.zeros(p)\n",
    "  rejections_nonpar_dvines[just_rejections_nonpar_dvines]=1\n",
    "    \n",
    "  #Power and FDP\n",
    "  np_nonpar_dvine_Power[k] = np.dot(rejections_nonpar_dvines, beta_dvine_order != 0) / (beta_dvine_order != 0).sum()\n",
    "  np_nonpar_dvine_FDP[k] = np.around(100*np.dot(rejections_nonpar_dvines, beta_dvine_order == 0) / max(1,rejections_nonpar_dvines.sum()))\n",
    "  print(f\"The NONPARAMETRIC DVINE knockoff filter POWER {100*np_nonpar_dvine_Power[k]}% with a FDP of {np_nonpar_dvine_FDP[k]}% (NONPAR DVINES)\")\n",
    "\n",
    "  #Deleting some objects\n",
    "  %R rm(dvine_distributions)  \n",
    "  \n",
    "  del X, y, beta, dvine_order\n",
    "  del rejections_gaussian,rejections_second_order,rejections_dvines, rejections_nonpar_dvines\n",
    "        \n",
    "  print(f\"LOOP ITERATION: {k}\")    \n",
    "\n",
    "time_knockoffs_2 = timer() - ti  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93db50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array of varying feature\n",
    "np_varying_feature = np.repeat([df_t],repeats=nsim,axis=0)\n",
    "\n",
    "\n",
    "#Dataframe with simulated data\n",
    "df_simulations_results_2 = pd.DataFrame({'Varying feature':np_varying_feature,                                    \n",
    "                     'Gaussian Power(%)':np_Gaussian_Power*100, \n",
    "                     '2do Order Power(%)':np_second_order_Power*100,\n",
    "                     'Dvine Power(%)':np_dvine_Power*100,\n",
    "                     'Nonpar DvinePower(%)':np_nonpar_dvine_Power*100,\n",
    "                     'Gaussian FDP(%)':np_Gaussian_FDP,\n",
    "                     '2do Order FDP(%)':np_second_order_FDP, \n",
    "                     'Dvine FDP(%)':np_dvine_FDP,\n",
    "                     'Nonpar Dvine FDP(%)':np_nonpar_dvine_FDP})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164aa656",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simulations_results_2.to_csv('t-Markov_results_2.csv')\n",
    "df_simulations_results_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc993bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_simulations_results_2.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dd6053",
   "metadata": {},
   "source": [
    "# Iteration 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c9f98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Degrees of fredom (t-distribution)\n",
    "df_t = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e75a12",
   "metadata": {},
   "source": [
    "### Data simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8261fc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arrays and lists to save information\n",
    "ls_simulations = list(range(nsim))\n",
    "ls_beta = list(range(nsim))\n",
    "ls_X = list(range(nsim))\n",
    "ls_y = list(range(nsim))\n",
    "\n",
    "ti = timer() #Initial time\n",
    "\n",
    "\n",
    "for k in range(nsim):\n",
    "  \n",
    "  #Set seed for replication \n",
    "  np.random.seed(k + ri + 3000) #Python\n",
    "  %R -i k\n",
    "  %R set.seed(k + ri + 3000)  #R\n",
    "\n",
    "  #X simulation according to a t-tailed Markov Chain\n",
    "  X = knockpy.dgp.sample_ar1t(rhos=np_rhos, n=n, df_t= df_t)\n",
    "  ls_X[k] = X  \n",
    "    \n",
    "  # Creating random sparse coefficients\n",
    "  beta = knockpy.dgp.create_sparse_coefficients(p=p, sparsity=sp, sign_prob=0.5, coeff_size=beta_factor,coeff_dist='uniform')\n",
    "  ls_beta[k] = beta\n",
    "\n",
    "  # Response variable\n",
    "  y = np.dot(X, beta) + np.random.randn(n)\n",
    "  ls_y[k] = y\n",
    "    \n",
    "  #Data frame with simulated data (Y,X)\n",
    "  #df_X = pd.DataFrame(X)\n",
    "  #df_y = pd.DataFrame(y)\n",
    "  #ls_simulations[k] = pd.concat([df_y,df_X], axis=1)\n",
    "\n",
    "time_simulations_3 = timer() - ti      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5aeff0c",
   "metadata": {},
   "source": [
    "### Knockoff filters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c1c92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# A list needed for the Gaussian Knockoff sampling procedure\n",
    "ls_Xk_norm <- list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d94242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_Gaussian_Power = np.zeros(nsim)\n",
    "np_Gaussian_FDP = np.zeros(nsim)\n",
    "\n",
    "np_second_order_Power = np.zeros(nsim)\n",
    "np_second_order_FDP = np.zeros(nsim)\n",
    "\n",
    "np_dvine_Power = np.zeros(nsim)\n",
    "np_dvine_FDP = np.zeros(nsim)\n",
    "\n",
    "np_nonpar_dvine_Power = np.zeros(nsim)\n",
    "np_nonpar_dvine_FDP = np.zeros(nsim)\n",
    "\n",
    "ti = timer() #Initial time\n",
    "\n",
    "for k in range(nsim):\n",
    "  \n",
    "  %R set.seed(NULL) #The R seed is set inside each knockoff filter function\n",
    "  \n",
    "  #Loading simulations  \n",
    "  X = ls_X[k]  \n",
    "  y = ls_y[k]\n",
    "  beta = ls_beta[k]\n",
    "    \n",
    "  #1)  \n",
    "  #Gaussian Knockoffs\n",
    "  \n",
    "  #Defining the Gaussian sampler object\n",
    "  Gaussian_sampler_hat = knockpy.knockoffs.GaussianSampler(X, mu=None,\n",
    "                                                           Sigma=None,\n",
    "                                                           method='mvr', verbose=False)\n",
    "\n",
    "  #Sampling the Gaussian Knockoffs\n",
    "  for m in range(M):\n",
    "      np.random.seed(m)\n",
    "      Xk_norm = Gaussian_sampler_hat.sample_knockoffs()\n",
    "      %R -i Xk_norm\n",
    "      %R -i m\n",
    "      %R ls_Xk_norm[[m+1]] <- Xk_norm\n",
    "      %R rm(Xk_norm)  \n",
    "    \n",
    "  #Array of integers that indicates the non-nulls position  \n",
    "  just_rejections_gaussian = gaussian_knockoff_filter(X, y, M, M_lasso, alpha, lasso_family, n_cores)\n",
    "  \n",
    "  print(\"Gaussian selection:\")  \n",
    "  print(np.sort(just_rejections_gaussian))\n",
    " \n",
    "  #Array that indicates the rejections considering all the variables (0 null, 1 non-null)\n",
    "  rejections_gaussian = np.zeros(p)\n",
    "  rejections_gaussian[just_rejections_gaussian]=1\n",
    "   \n",
    "\n",
    "  #Power and FDP\n",
    "  np_Gaussian_Power[k] = np.dot(rejections_gaussian, beta != 0) / (beta != 0).sum()\n",
    "  np_Gaussian_FDP[k] = np.around(100*np.dot(rejections_gaussian, beta == 0) / max(1,rejections_gaussian.sum() ) )\n",
    "  print(f\"The knockoff GAUSSIAN filter POWER {100*np_Gaussian_Power[k]}% with a FDP of {np_Gaussian_FDP[k]}%\")\n",
    "  \n",
    "\n",
    "  #2)\n",
    "  #Second order knockoff filter    \n",
    "  just_rejections_second_order = second_order_knockoff_filter(X, y, M, M_lasso, alpha, lasso_family, n_cores)\n",
    "  \n",
    "  #Array of integers that indicates the non-nulls position\n",
    "  print(\"Second Order selection:\")  \n",
    "  print(np.sort(just_rejections_second_order))\n",
    "  \n",
    "  #Array that indicates the rejections considering all the variables (0 null, 1 non-null)\n",
    "  rejections_second_order = np.zeros(p)\n",
    "  rejections_second_order[just_rejections_second_order]=1\n",
    "    \n",
    "  #Power and FDP\n",
    "  np_second_order_Power[k] = np.dot(rejections_second_order, beta != 0) / (beta != 0).sum()\n",
    "  np_second_order_FDP[k] = np.around(100*np.dot(rejections_second_order, beta == 0) / max(1,rejections_second_order.sum()))\n",
    "  print(f\"The knockoff SECOND ORDER filter POWER {100*np_second_order_Power[k]}% with a FDP of {np_second_order_FDP[k]}%\")\n",
    "    \n",
    "  #3) dvine_order\n",
    "  #Heuristic procedure to determine the order for the first tree in a D-vine structure\n",
    "  dvine_order = get_dvine_order(X)\n",
    "\n",
    "  #New columns orders for X and beta\n",
    "  X_dvine_order = X[:,dvine_order]\n",
    "  beta_dvine_order  = beta[dvine_order]\n",
    "\n",
    "  #4) Parametric dvine\n",
    "    \n",
    "  just_rejections_dvines = dvine_knockoff_filter(X_dvine_order, y, M, M_lasso, alpha, lasso_family, vinecop_family, n_cores)\n",
    "    \n",
    "  #Array of integers that indicates the non-nulls position\n",
    "  print(\"DVINE selection (in dvine_order):\")\n",
    "  print(np.sort(just_rejections_dvines))\n",
    " \n",
    "  #Array that indicates the rejections considering all the variables (0 null, 1 non-null)\n",
    "  rejections_dvines = np.zeros(p)\n",
    "  rejections_dvines[just_rejections_dvines]=1\n",
    "    \n",
    "  #Power and FDP\n",
    "  np_dvine_Power[k] = np.dot(rejections_dvines, beta_dvine_order != 0) / (beta_dvine_order != 0).sum()\n",
    "  np_dvine_FDP[k] = np.around(100*np.dot(rejections_dvines, beta_dvine_order == 0) / max(1,rejections_dvines.sum()))\n",
    "  print(f\"The DVINE knockoff filter POWER {100*np_dvine_Power[k]}% with a FDP of {np_dvine_FDP[k]}% (DVINES)\")\n",
    "\n",
    "  #Deleting some objects\n",
    "  %R rm(dvine_distributions)  \n",
    "\n",
    "  #5) Nonparametric dvine\n",
    "  #dvine knockoff filter  \n",
    "  just_rejections_nonpar_dvines = dvine_knockoff_filter(X_dvine_order, y, M, M_lasso, alpha, lasso_family, nonparametric_family, n_cores)\n",
    "    \n",
    "  #Array of integers that indicates the non-nulls position\n",
    "  print(\"NONPARAMETRIC DVINE selection (in dvine_order):\")\n",
    "  print(np.sort(just_rejections_nonpar_dvines))\n",
    " \n",
    "  #Array that indicates the rejections considering all the variables (0 null, 1 non-null)\n",
    "  rejections_nonpar_dvines = np.zeros(p)\n",
    "  rejections_nonpar_dvines[just_rejections_nonpar_dvines]=1\n",
    "    \n",
    "  #Power and FDP\n",
    "  np_nonpar_dvine_Power[k] = np.dot(rejections_nonpar_dvines, beta_dvine_order != 0) / (beta_dvine_order != 0).sum()\n",
    "  np_nonpar_dvine_FDP[k] = np.around(100*np.dot(rejections_nonpar_dvines, beta_dvine_order == 0) / max(1,rejections_nonpar_dvines.sum()))\n",
    "  print(f\"The NONPARAMETRIC DVINE knockoff filter POWER {100*np_nonpar_dvine_Power[k]}% with a FDP of {np_nonpar_dvine_FDP[k]}% (NONPAR DVINES)\")\n",
    "\n",
    "  #Deleting some objects\n",
    "  %R rm(dvine_distributions)  \n",
    "  \n",
    "  del X, y, beta, dvine_order\n",
    "  del rejections_gaussian,rejections_second_order,rejections_dvines, rejections_nonpar_dvines\n",
    "        \n",
    "  print(f\"LOOP ITERATION: {k}\")    \n",
    "  \n",
    "time_knockoffs_3 = timer() - ti  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603e38e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array of varying feature\n",
    "np_varying_feature = np.repeat([df_t],repeats=nsim,axis=0)\n",
    "\n",
    "\n",
    "#Dataframe with simulated data\n",
    "df_simulations_results_3 = pd.DataFrame({'Varying feature':np_varying_feature,                                    \n",
    "                     'Gaussian Power(%)':np_Gaussian_Power*100, \n",
    "                     '2do Order Power(%)':np_second_order_Power*100,\n",
    "                     'Dvine Power(%)':np_dvine_Power*100,\n",
    "                     'Nonpar DvinePower(%)':np_nonpar_dvine_Power*100,\n",
    "                     'Gaussian FDP(%)':np_Gaussian_FDP,\n",
    "                     '2do Order FDP(%)':np_second_order_FDP, \n",
    "                     'Dvine FDP(%)':np_dvine_FDP,\n",
    "                     'Nonpar Dvine FDP(%)':np_nonpar_dvine_FDP})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58066a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simulations_results_3.to_csv('t-Markov_results_3.csv')\n",
    "df_simulations_results_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b247bb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_simulations_results_3.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f3bcec",
   "metadata": {},
   "source": [
    "# Iteration 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdb8b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Degrees of fredom (t-distribution)\n",
    "df_t = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bf7561",
   "metadata": {},
   "source": [
    "### Data simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e643613",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arrays and lists to save information\n",
    "ls_simulations = list(range(nsim))\n",
    "ls_beta = list(range(nsim))\n",
    "ls_X = list(range(nsim))\n",
    "ls_y = list(range(nsim))\n",
    "\n",
    "ti = timer() #Initial time\n",
    "\n",
    "\n",
    "for k in range(nsim):\n",
    "  \n",
    "  #Set seed for replication \n",
    "  np.random.seed(k + ri + 4000) #Python\n",
    "  %R -i k\n",
    "  %R set.seed(k + ri + 4000)  #R\n",
    "\n",
    "  #X simulation according to a t-tailed Markov Chain\n",
    "  X = knockpy.dgp.sample_ar1t(rhos=np_rhos, n=n, df_t= df_t)\n",
    "  ls_X[k] = X  \n",
    "    \n",
    "  # Creating random sparse coefficients\n",
    "  beta = knockpy.dgp.create_sparse_coefficients(p=p, sparsity=sp, sign_prob=0.5, coeff_size=beta_factor,coeff_dist='uniform')\n",
    "  ls_beta[k] = beta\n",
    "\n",
    "  # Response variable\n",
    "  y = np.dot(X, beta) + np.random.randn(n)\n",
    "  ls_y[k] = y\n",
    "    \n",
    "  #Data frame with simulated data (Y,X)\n",
    "  #df_X = pd.DataFrame(X)\n",
    "  #df_y = pd.DataFrame(y)\n",
    "  #ls_simulations[k] = pd.concat([df_y,df_X], axis=1)\n",
    "\n",
    "time_simulations_4 = timer() - ti      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f38355",
   "metadata": {},
   "source": [
    "### Knockoff filters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72eedf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# A list needed for the Gaussian Knockoff sampling procedure\n",
    "ls_Xk_norm <- list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4858731b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_Gaussian_Power = np.zeros(nsim)\n",
    "np_Gaussian_FDP = np.zeros(nsim)\n",
    "\n",
    "np_second_order_Power = np.zeros(nsim)\n",
    "np_second_order_FDP = np.zeros(nsim)\n",
    "\n",
    "np_dvine_Power = np.zeros(nsim)\n",
    "np_dvine_FDP = np.zeros(nsim)\n",
    "\n",
    "np_nonpar_dvine_Power = np.zeros(nsim)\n",
    "np_nonpar_dvine_FDP = np.zeros(nsim)\n",
    "\n",
    "ti = timer() #Initial time\n",
    "\n",
    "for k in range(nsim):\n",
    "  \n",
    "  %R set.seed(NULL) #The R seed is set inside each knockoff filter function\n",
    "  \n",
    "  #Loading simulations  \n",
    "  X = ls_X[k]  \n",
    "  y = ls_y[k]\n",
    "  beta = ls_beta[k]\n",
    "    \n",
    "  #1)  \n",
    "  #Gaussian Knockoffs\n",
    "  \n",
    "  #Defining the Gaussian sampler object\n",
    "  Gaussian_sampler_hat = knockpy.knockoffs.GaussianSampler(X, mu=None,\n",
    "                                                           Sigma=None,\n",
    "                                                           method='mvr', verbose=False)\n",
    "\n",
    "  #Sampling the Gaussian Knockoffs\n",
    "  for m in range(M):\n",
    "      np.random.seed(m)\n",
    "      Xk_norm = Gaussian_sampler_hat.sample_knockoffs()\n",
    "      %R -i Xk_norm\n",
    "      %R -i m\n",
    "      %R ls_Xk_norm[[m+1]] <- Xk_norm\n",
    "      %R rm(Xk_norm)  \n",
    "    \n",
    "  #Array of integers that indicates the non-nulls position  \n",
    "  just_rejections_gaussian = gaussian_knockoff_filter(X, y, M, M_lasso, alpha, lasso_family, n_cores)\n",
    "  \n",
    "  print(\"Gaussian selection:\")  \n",
    "  print(np.sort(just_rejections_gaussian))\n",
    " \n",
    "  #Array that indicates the rejections considering all the variables (0 null, 1 non-null)\n",
    "  rejections_gaussian = np.zeros(p)\n",
    "  rejections_gaussian[just_rejections_gaussian]=1\n",
    "   \n",
    "\n",
    "  #Power and FDP\n",
    "  np_Gaussian_Power[k] = np.dot(rejections_gaussian, beta != 0) / (beta != 0).sum()\n",
    "  np_Gaussian_FDP[k] = np.around(100*np.dot(rejections_gaussian, beta == 0) / max(1,rejections_gaussian.sum() ) )\n",
    "  print(f\"The knockoff GAUSSIAN filter POWER {100*np_Gaussian_Power[k]}% with a FDP of {np_Gaussian_FDP[k]}%\")\n",
    "  \n",
    "\n",
    "  #2)\n",
    "  #Second order knockoff filter    \n",
    "  just_rejections_second_order = second_order_knockoff_filter(X, y, M, M_lasso, alpha, lasso_family, n_cores)\n",
    "  \n",
    "  #Array of integers that indicates the non-nulls position\n",
    "  print(\"Second Order selection:\")  \n",
    "  print(np.sort(just_rejections_second_order))\n",
    "  \n",
    "  #Array that indicates the rejections considering all the variables (0 null, 1 non-null)\n",
    "  rejections_second_order = np.zeros(p)\n",
    "  rejections_second_order[just_rejections_second_order]=1\n",
    "    \n",
    "  #Power and FDP\n",
    "  np_second_order_Power[k] = np.dot(rejections_second_order, beta != 0) / (beta != 0).sum()\n",
    "  np_second_order_FDP[k] = np.around(100*np.dot(rejections_second_order, beta == 0) / max(1,rejections_second_order.sum()))\n",
    "  print(f\"The knockoff SECOND ORDER filter POWER {100*np_second_order_Power[k]}% with a FDP of {np_second_order_FDP[k]}%\")\n",
    "    \n",
    "  #3) dvine_order\n",
    "  #Heuristic procedure to determine the order for the first tree in a D-vine structure\n",
    "  dvine_order = get_dvine_order(X)\n",
    "\n",
    "  #New columns orders for X and beta\n",
    "  X_dvine_order = X[:,dvine_order]\n",
    "  beta_dvine_order  = beta[dvine_order]\n",
    "\n",
    "  #4) Parametric dvine\n",
    "    \n",
    "  just_rejections_dvines = dvine_knockoff_filter(X_dvine_order, y, M, M_lasso, alpha, lasso_family, vinecop_family, n_cores)\n",
    "    \n",
    "  #Array of integers that indicates the non-nulls position\n",
    "  print(\"DVINE selection (in dvine_order):\")\n",
    "  print(np.sort(just_rejections_dvines))\n",
    " \n",
    "  #Array that indicates the rejections considering all the variables (0 null, 1 non-null)\n",
    "  rejections_dvines = np.zeros(p)\n",
    "  rejections_dvines[just_rejections_dvines]=1\n",
    "    \n",
    "  #Power and FDP\n",
    "  np_dvine_Power[k] = np.dot(rejections_dvines, beta_dvine_order != 0) / (beta_dvine_order != 0).sum()\n",
    "  np_dvine_FDP[k] = np.around(100*np.dot(rejections_dvines, beta_dvine_order == 0) / max(1,rejections_dvines.sum()))\n",
    "  print(f\"The DVINE knockoff filter POWER {100*np_dvine_Power[k]}% with a FDP of {np_dvine_FDP[k]}% (DVINES)\")\n",
    "\n",
    "  #Deleting some objects\n",
    "  %R rm(dvine_distributions)  \n",
    "\n",
    "  #5) Nonparametric dvine\n",
    "  #dvine knockoff filter  \n",
    "  just_rejections_nonpar_dvines = dvine_knockoff_filter(X_dvine_order, y, M, M_lasso, alpha, lasso_family, nonparametric_family, n_cores)\n",
    "    \n",
    "  #Array of integers that indicates the non-nulls position\n",
    "  print(\"NONPARAMETRIC DVINE selection (in dvine_order):\")\n",
    "  print(np.sort(just_rejections_nonpar_dvines))\n",
    " \n",
    "  #Array that indicates the rejections considering all the variables (0 null, 1 non-null)\n",
    "  rejections_nonpar_dvines = np.zeros(p)\n",
    "  rejections_nonpar_dvines[just_rejections_nonpar_dvines]=1\n",
    "    \n",
    "  #Power and FDP\n",
    "  np_nonpar_dvine_Power[k] = np.dot(rejections_nonpar_dvines, beta_dvine_order != 0) / (beta_dvine_order != 0).sum()\n",
    "  np_nonpar_dvine_FDP[k] = np.around(100*np.dot(rejections_nonpar_dvines, beta_dvine_order == 0) / max(1,rejections_nonpar_dvines.sum()))\n",
    "  print(f\"The NONPARAMETRIC DVINE knockoff filter POWER {100*np_nonpar_dvine_Power[k]}% with a FDP of {np_nonpar_dvine_FDP[k]}% (NONPAR DVINES)\")\n",
    "\n",
    "  #Deleting some objects\n",
    "  %R rm(dvine_distributions)  \n",
    "  \n",
    "  del X, y, beta, dvine_order\n",
    "  del rejections_gaussian,rejections_second_order,rejections_dvines, rejections_nonpar_dvines\n",
    "        \n",
    "  print(f\"LOOP ITERATION: {k}\")\n",
    " \n",
    "time_knockoffs_4 = timer() - ti  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee947a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array of varying feature\n",
    "np_varying_feature = np.repeat([df_t],repeats=nsim,axis=0)\n",
    "\n",
    "\n",
    "#Dataframe with simulated data\n",
    "df_simulations_results_4 = pd.DataFrame({'Varying feature':np_varying_feature,                                      \n",
    "                     'Gaussian Power(%)':np_Gaussian_Power*100, \n",
    "                     '2do Order Power(%)':np_second_order_Power*100,\n",
    "                     'Dvine Power(%)':np_dvine_Power*100,\n",
    "                     'Nonpar DvinePower(%)':np_nonpar_dvine_Power*100,\n",
    "                     'Gaussian FDP(%)':np_Gaussian_FDP,\n",
    "                     '2do Order FDP(%)':np_second_order_FDP, \n",
    "                     'Dvine FDP(%)':np_dvine_FDP,\n",
    "                     'Nonpar Dvine FDP(%)':np_nonpar_dvine_FDP})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2210ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simulations_results_4.to_csv('t-Markov_results_4.csv')\n",
    "df_simulations_results_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77589071",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simulations_results_4.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58acf656",
   "metadata": {},
   "source": [
    "# Iteration 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa671d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Degrees of fredom (t-distribution)\n",
    "df_t = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aedabd",
   "metadata": {},
   "source": [
    "### Data simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53422b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arrays and lists to save information\n",
    "ls_simulations = list(range(nsim))\n",
    "ls_beta = list(range(nsim))\n",
    "ls_X = list(range(nsim))\n",
    "ls_y = list(range(nsim))\n",
    "\n",
    "ti = timer() #Initial time\n",
    "\n",
    "\n",
    "for k in range(nsim):\n",
    "  \n",
    "  #Set seed for replication \n",
    "  np.random.seed(k + ri + 5000) #Python\n",
    "  %R -i k\n",
    "  %R set.seed(k + ri + 5000)  #R\n",
    "\n",
    "  #X simulation according to a t-tailed Markov Chain\n",
    "  X = knockpy.dgp.sample_ar1t(rhos=np_rhos, n=n, df_t= df_t)\n",
    "  ls_X[k] = X  \n",
    "    \n",
    "  # Creating random sparse coefficients\n",
    "  beta = knockpy.dgp.create_sparse_coefficients(p=p, sparsity=sp, sign_prob=0.5, coeff_size=beta_factor,coeff_dist='uniform')\n",
    "  ls_beta[k] = beta\n",
    "\n",
    "  # Response variable\n",
    "  y = np.dot(X, beta) + np.random.randn(n)\n",
    "  ls_y[k] = y\n",
    "    \n",
    "  #Data frame with simulated data (Y,X)\n",
    "  #df_X = pd.DataFrame(X)\n",
    "  #df_y = pd.DataFrame(y)\n",
    "  #ls_simulations[k] = pd.concat([df_y,df_X], axis=1)\n",
    "\n",
    "time_simulations_5 = timer() - ti      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2020fe0c",
   "metadata": {},
   "source": [
    "### Knockoff filters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7745b900",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# A list needed for the Gaussian Knockoff sampling procedure\n",
    "ls_Xk_norm <- list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769f9dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_Gaussian_Power = np.zeros(nsim)\n",
    "np_Gaussian_FDP = np.zeros(nsim)\n",
    "\n",
    "np_second_order_Power = np.zeros(nsim)\n",
    "np_second_order_FDP = np.zeros(nsim)\n",
    "\n",
    "np_dvine_Power = np.zeros(nsim)\n",
    "np_dvine_FDP = np.zeros(nsim)\n",
    "\n",
    "np_nonpar_dvine_Power = np.zeros(nsim)\n",
    "np_nonpar_dvine_FDP = np.zeros(nsim)\n",
    "\n",
    "ti = timer() #Initial time\n",
    "\n",
    "for k in range(nsim):\n",
    "  \n",
    "  %R set.seed(NULL) #The R seed is set inside each knockoff filter function\n",
    "  \n",
    "  #Loading simulations  \n",
    "  X = ls_X[k]  \n",
    "  y = ls_y[k]\n",
    "  beta = ls_beta[k]\n",
    "    \n",
    "  #1)  \n",
    "  #Gaussian Knockoffs\n",
    "  \n",
    "  #Defining the Gaussian sampler object\n",
    "  Gaussian_sampler_hat = knockpy.knockoffs.GaussianSampler(X, mu=None,\n",
    "                                                           Sigma=None,\n",
    "                                                           method='mvr', verbose=False)\n",
    "\n",
    "  #Sampling the Gaussian Knockoffs\n",
    "  for m in range(M):\n",
    "      np.random.seed(m)\n",
    "      Xk_norm = Gaussian_sampler_hat.sample_knockoffs()\n",
    "      %R -i Xk_norm\n",
    "      %R -i m\n",
    "      %R ls_Xk_norm[[m+1]] <- Xk_norm\n",
    "      %R rm(Xk_norm)  \n",
    "    \n",
    "  #Array of integers that indicates the non-nulls position  \n",
    "  just_rejections_gaussian = gaussian_knockoff_filter(X, y, M, M_lasso, alpha, lasso_family, n_cores)\n",
    "  \n",
    "  print(\"Gaussian selection:\")  \n",
    "  print(np.sort(just_rejections_gaussian))\n",
    " \n",
    "  #Array that indicates the rejections considering all the variables (0 null, 1 non-null)\n",
    "  rejections_gaussian = np.zeros(p)\n",
    "  rejections_gaussian[just_rejections_gaussian]=1\n",
    "   \n",
    "\n",
    "  #Power and FDP\n",
    "  np_Gaussian_Power[k] = np.dot(rejections_gaussian, beta != 0) / (beta != 0).sum()\n",
    "  np_Gaussian_FDP[k] = np.around(100*np.dot(rejections_gaussian, beta == 0) / max(1,rejections_gaussian.sum() ) )\n",
    "  print(f\"The knockoff GAUSSIAN filter POWER {100*np_Gaussian_Power[k]}% with a FDP of {np_Gaussian_FDP[k]}%\")\n",
    "  \n",
    "\n",
    "  #2)\n",
    "  #Second order knockoff filter    \n",
    "  just_rejections_second_order = second_order_knockoff_filter(X, y, M, M_lasso, alpha, lasso_family, n_cores)\n",
    "  \n",
    "  #Array of integers that indicates the non-nulls position\n",
    "  print(\"Second Order selection:\")  \n",
    "  print(np.sort(just_rejections_second_order))\n",
    "  \n",
    "  #Array that indicates the rejections considering all the variables (0 null, 1 non-null)\n",
    "  rejections_second_order = np.zeros(p)\n",
    "  rejections_second_order[just_rejections_second_order]=1\n",
    "    \n",
    "  #Power and FDP\n",
    "  np_second_order_Power[k] = np.dot(rejections_second_order, beta != 0) / (beta != 0).sum()\n",
    "  np_second_order_FDP[k] = np.around(100*np.dot(rejections_second_order, beta == 0) / max(1,rejections_second_order.sum()))\n",
    "  print(f\"The knockoff SECOND ORDER filter POWER {100*np_second_order_Power[k]}% with a FDP of {np_second_order_FDP[k]}%\")\n",
    "    \n",
    "  #3) dvine_order\n",
    "  #Heuristic procedure to determine the order for the first tree in a D-vine structure\n",
    "  dvine_order = get_dvine_order(X)\n",
    "\n",
    "  #New columns orders for X and beta\n",
    "  X_dvine_order = X[:,dvine_order]\n",
    "  beta_dvine_order  = beta[dvine_order]\n",
    "\n",
    "  #4) Parametric dvine\n",
    "    \n",
    "  just_rejections_dvines = dvine_knockoff_filter(X_dvine_order, y, M, M_lasso, alpha, lasso_family, vinecop_family, n_cores)\n",
    "    \n",
    "  #Array of integers that indicates the non-nulls position\n",
    "  print(\"DVINE selection (in dvine_order):\")\n",
    "  print(np.sort(just_rejections_dvines))\n",
    " \n",
    "  #Array that indicates the rejections considering all the variables (0 null, 1 non-null)\n",
    "  rejections_dvines = np.zeros(p)\n",
    "  rejections_dvines[just_rejections_dvines]=1\n",
    "    \n",
    "  #Power and FDP\n",
    "  np_dvine_Power[k] = np.dot(rejections_dvines, beta_dvine_order != 0) / (beta_dvine_order != 0).sum()\n",
    "  np_dvine_FDP[k] = np.around(100*np.dot(rejections_dvines, beta_dvine_order == 0) / max(1,rejections_dvines.sum()))\n",
    "  print(f\"The DVINE knockoff filter POWER {100*np_dvine_Power[k]}% with a FDP of {np_dvine_FDP[k]}% (DVINES)\")\n",
    "\n",
    "  #Deleting some objects\n",
    "  %R rm(dvine_distributions)  \n",
    "\n",
    "  #5) Nonparametric dvine\n",
    "  #dvine knockoff filter  \n",
    "  just_rejections_nonpar_dvines = dvine_knockoff_filter(X_dvine_order, y, M, M_lasso, alpha, lasso_family, nonparametric_family, n_cores)\n",
    "    \n",
    "  #Array of integers that indicates the non-nulls position\n",
    "  print(\"NONPARAMETRIC DVINE selection (in dvine_order):\")\n",
    "  print(np.sort(just_rejections_nonpar_dvines))\n",
    " \n",
    "  #Array that indicates the rejections considering all the variables (0 null, 1 non-null)\n",
    "  rejections_nonpar_dvines = np.zeros(p)\n",
    "  rejections_nonpar_dvines[just_rejections_nonpar_dvines]=1\n",
    "    \n",
    "  #Power and FDP\n",
    "  np_nonpar_dvine_Power[k] = np.dot(rejections_nonpar_dvines, beta_dvine_order != 0) / (beta_dvine_order != 0).sum()\n",
    "  np_nonpar_dvine_FDP[k] = np.around(100*np.dot(rejections_nonpar_dvines, beta_dvine_order == 0) / max(1,rejections_nonpar_dvines.sum()))\n",
    "  print(f\"The NONPARAMETRIC DVINE knockoff filter POWER {100*np_nonpar_dvine_Power[k]}% with a FDP of {np_nonpar_dvine_FDP[k]}% (NONPAR DVINES)\")\n",
    "\n",
    "  #Deleting some objects\n",
    "  %R rm(dvine_distributions)  \n",
    "  \n",
    "  del X, y, beta, dvine_order\n",
    "  del rejections_gaussian,rejections_second_order,rejections_dvines, rejections_nonpar_dvines\n",
    "        \n",
    "  print(f\"LOOP ITERATION: {k}\")    \n",
    "\n",
    "time_knockoffs_5 = timer() - ti  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31162be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array of varying feature\n",
    "np_varying_feature = np.repeat([df_t],repeats=nsim,axis=0)\n",
    "\n",
    "\n",
    "#Dataframe with simulated data\n",
    "df_simulations_results_5 = pd.DataFrame({'Varying feature':np_varying_feature,                                     \n",
    "                     'Gaussian Power(%)':np_Gaussian_Power*100, \n",
    "                     '2do Order Power(%)':np_second_order_Power*100,\n",
    "                     'Dvine Power(%)':np_dvine_Power*100,\n",
    "                     'Nonpar DvinePower(%)':np_nonpar_dvine_Power*100,\n",
    "                     'Gaussian FDP(%)':np_Gaussian_FDP,\n",
    "                     '2do Order FDP(%)':np_second_order_FDP, \n",
    "                     'Dvine FDP(%)':np_dvine_FDP,\n",
    "                     'Nonpar Dvine FDP(%)':np_nonpar_dvine_FDP})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701025e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simulations_results_5.to_csv('t-Markov_results_5.csv')\n",
    "df_simulations_results_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0842a66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_simulations_results_5.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292da20b",
   "metadata": {},
   "source": [
    "### Time to run all the scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4213c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_final = timer()\n",
    "\n",
    "print('Time (hrs) taken to run all is:',round((t_final-t_initial)/3600,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bc3849",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run time of the different loops\n",
    "\n",
    "time_simulations = time_simulations_1 +time_simulations_2 + time_simulations_3 + time_simulations_4 + time_simulations_5   \n",
    "print('Time (hrs) taken to create simulations of X and y:',round(time_simulations/3600,4))\n",
    "\n",
    "time_knockoffs = time_knockoffs_1 +time_knockoffs_2 + time_knockoffs_3 + time_knockoffs_4 + time_knockoffs_5  \n",
    "print('Time (hrs) taken to apply knockoffs filters:',round(time_knockoffs/3600,4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b37ff09",
   "metadata": {},
   "source": [
    "# Bringing it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0913a575",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data frame with \n",
    "df_simulations_results = pd.concat([df_simulations_results_1,df_simulations_results_2,df_simulations_results_3,df_simulations_results_4,df_simulations_results_5], axis=0)\n",
    "df_simulations_results.reset_index(drop=True, inplace=True)\n",
    "df_simulations_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e7d312",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = df_simulations_results[[\"Varying feature\",\"Gaussian Power(%)\",\"2do Order Power(%)\", \"Dvine Power(%)\", \"Nonpar DvinePower(%)\", \"Gaussian FDP(%)\", \"2do Order FDP(%)\",\"Dvine FDP(%)\",\"Nonpar Dvine FDP(%)\"]].groupby(\"Varying feature\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c402c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
